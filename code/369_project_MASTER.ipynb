{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fa9709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem       Size   Used  Avail Capacity iused      ifree %iused  Mounted on\n",
      "/dev/disk3s1s1  460Gi   15Gi  150Gi     9%  575614 1572258520    0%   /\n",
      "devfs           201Ki  201Ki    0Bi   100%     698          0  100%   /dev\n",
      "/dev/disk3s6    460Gi   20Ki  150Gi     1%       0 1572258520    0%   /System/Volumes/VM\n",
      "/dev/disk3s2    460Gi  302Mi  150Gi     1%     749 1572258520    0%   /System/Volumes/Preboot\n",
      "/dev/disk3s4    460Gi  980Ki  150Gi     1%      40 1572258520    0%   /System/Volumes/Update\n",
      "/dev/disk1s2    500Mi  6.0Mi  480Mi     2%       1    4914080    0%   /System/Volumes/xarts\n",
      "/dev/disk1s1    500Mi  7.3Mi  480Mi     2%      30    4914080    0%   /System/Volumes/iSCPreboot\n",
      "/dev/disk1s3    500Mi  2.0Mi  480Mi     1%      49    4914080    0%   /System/Volumes/Hardware\n",
      "/dev/disk3s5    460Gi  295Gi  150Gi    67%  875280 1572258520    0%   /System/Volumes/Data\n",
      "map auto_home     0Bi    0Bi    0Bi   100%       0          0  100%   /System/Volumes/Data/home\n"
     ]
    }
   ],
   "source": [
    "## See storage available\n",
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0e48aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machdep.cpu.brand_string: Apple M1 Pro\n",
      "machdep.cpu.core_count: 8\n",
      "machdep.cpu.cores_per_package: 8\n",
      "machdep.cpu.logical_per_package: 8\n",
      "machdep.cpu.thread_count: 8\n"
     ]
    }
   ],
   "source": [
    "# See CPUs available (mac)\n",
    "!sysctl -a | grep machdep.cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e579c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free:                     1286.69 Mi\n",
      "active:                   3687.62 Mi\n",
      "inactive:                 5377.00 Mi\n",
      "speculative:              2831.34 Mi\n",
      "throttled:                   0.00 Mi\n",
      "wired down:               1249.98 Mi\n",
      "purgeable:                  16.67 Mi\n",
      "copy-on-write:            4259.81 Mi\n",
      "zero filled:             65107.00 Mi\n",
      "reactivated:              7779.62 Mi\n",
      "purged:                    306.25 Mi\n",
      "stored in compressor:          3405.31 Mi\n",
      "occupied by compressor:          1336.22 Mi\n"
     ]
    }
   ],
   "source": [
    "# See memory available (mac)\n",
    "!vm_stat | perl -ne '/page size of (\\d+)/ and $size=$1; /Pages\\s+([^:]+)[^\\d]+(\\d+)/ and printf(\"%-16s % 16.2f Mi\\n\", \"$1:\", $2 * $size / 1048576);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37b68a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/10 17:08:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# MISC\n",
    "import gzip\n",
    "import multiprocessing\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "cpu_cores = multiprocessing.cpu_count()\n",
    "data_path_50MB = '/Users/angelloparr/Documents/csc369/project.nosync/data_uncompressed/Gift_Cards.json'\n",
    "data_path_263MB = '/Users/angelloparr/Documents/csc369/project.nosync/data_uncompressed/Appliances.json'\n",
    "data_path_755MB = '/Users/angelloparr/Documents/csc369/project.nosync/data_uncompressed/Digital_Music.json'\n",
    "data_path_2GB = '/Users/angelloparr/Documents/csc369/project.nosync/data_uncompressed/Video_Games.json'\n",
    "data_path_10GB = '/Users/angelloparr/Documents/csc369/project.nosync/data_uncompressed/reviews_Books_1.json'\n",
    "data_path_38GB = '/Users/angelloparr/Documents/csc369/project.nosync/data_uncompressed/Books_big.json'\n",
    "\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "import dask.bag as db\n",
    "dask.config.set(scheduler='processes', num_workers=cpu_cores)\n",
    "\n",
    "# Spark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f221ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func, args):\n",
    "    start = time.time()\n",
    "    res = func(args)\n",
    "    elapsed = time.time() - start\n",
    "    log_line = f'Elapsed time for {func}: {elapsed}'\n",
    "    return {'res': res, 'elapsed': elapsed, 'log': log_line}\n",
    "\n",
    "def get_elapsed(start):\n",
    "    return time.time() - start\n",
    "\n",
    "def print_elapsed(start):\n",
    "    elapsed = time.time() - start\n",
    "    print(f'Elapsed time for operation: {elapsed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab2b6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>12 19, 2008</td>\n",
       "      <td>APV13CM0919JD</td>\n",
       "      <td>B001GXRQW0</td>\n",
       "      <td>{'Gift Amount:': ' 50'}</td>\n",
       "      <td>LEH</td>\n",
       "      <td>Amazon,\\nI am shopping for Amazon.com gift car...</td>\n",
       "      <td>Merry Christmas.</td>\n",
       "      <td>1229644800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>12 17, 2008</td>\n",
       "      <td>A3G8U1G1V082SN</td>\n",
       "      <td>B001GXRQW0</td>\n",
       "      <td>{'Gift Amount:': ' 50'}</td>\n",
       "      <td>Tali</td>\n",
       "      <td>I got this gift card from a friend, and it was...</td>\n",
       "      <td>Gift card with best selection</td>\n",
       "      <td>1229472000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>12 17, 2008</td>\n",
       "      <td>A11T2Q0EVTUWP</td>\n",
       "      <td>B001GXRQW0</td>\n",
       "      <td>{'Gift Amount:': ' 50'}</td>\n",
       "      <td>Z</td>\n",
       "      <td>aren't we going to save trees?! :) People who ...</td>\n",
       "      <td>A convenient and great gift for the environmen...</td>\n",
       "      <td>1229472000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>12 17, 2008</td>\n",
       "      <td>A9YKGBH3SV22C</td>\n",
       "      <td>B001GXRQW0</td>\n",
       "      <td>{'Gift Amount:': ' 25'}</td>\n",
       "      <td>Giotravels</td>\n",
       "      <td>You can always get someone something from Amaz...</td>\n",
       "      <td>Totally make sense</td>\n",
       "      <td>1229472000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>12 17, 2008</td>\n",
       "      <td>A34WZIHVF3OKOL</td>\n",
       "      <td>B001GXRQW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>King Dad</td>\n",
       "      <td>Why take 50 dollars of good money with no limi...</td>\n",
       "      <td>Give CASH!</td>\n",
       "      <td>1229472000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0        1   25     False  12 19, 2008   APV13CM0919JD  B001GXRQW0   \n",
       "1        5  NaN     False  12 17, 2008  A3G8U1G1V082SN  B001GXRQW0   \n",
       "2        5    4     False  12 17, 2008   A11T2Q0EVTUWP  B001GXRQW0   \n",
       "3        5  NaN     False  12 17, 2008   A9YKGBH3SV22C  B001GXRQW0   \n",
       "4        1  NaN      True  12 17, 2008  A34WZIHVF3OKOL  B001GXRQW0   \n",
       "\n",
       "                     style reviewerName  \\\n",
       "0  {'Gift Amount:': ' 50'}          LEH   \n",
       "1  {'Gift Amount:': ' 50'}         Tali   \n",
       "2  {'Gift Amount:': ' 50'}            Z   \n",
       "3  {'Gift Amount:': ' 25'}   Giotravels   \n",
       "4                      NaN     King Dad   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Amazon,\\nI am shopping for Amazon.com gift car...   \n",
       "1  I got this gift card from a friend, and it was...   \n",
       "2  aren't we going to save trees?! :) People who ...   \n",
       "3  You can always get someone something from Amaz...   \n",
       "4  Why take 50 dollars of good money with no limi...   \n",
       "\n",
       "                                             summary  unixReviewTime image  \n",
       "0                                   Merry Christmas.      1229644800   NaN  \n",
       "1                      Gift card with best selection      1229472000   NaN  \n",
       "2  A convenient and great gift for the environmen...      1229472000   NaN  \n",
       "3                                 Totally make sense      1229472000   NaN  \n",
       "4                                         Give CASH!      1229472000   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_json(data_path_50MB, orient='records', lines=True)\n",
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe3380",
   "metadata": {},
   "source": [
    "## Pandas Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec0df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for operation: 0.003943920135498047\n",
      "Elapsed time for operation: 0.02343606948852539\n",
      "Elapsed time for operation: 13.133556842803955\n",
      "Elapsed time for operation: 47.215304136276245\n",
      "Elapsed time for operation: 14.041398048400879\n",
      "Elapsed time for operation: 3.146782159805298\n",
      "Total execution time: 77.99114394187927\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "start = begin\n",
    "\n",
    "## Drop unwanted columns / keep good ones\n",
    "columns = ['reviewerID', 'reviewText']\n",
    "reviews_df = reviews_df[columns]\n",
    "print_elapsed(start)\n",
    "\n",
    "## Drop empty (NaN) rows\n",
    "start = time.time()\n",
    "reviews_df = reviews_df.dropna()\n",
    "print_elapsed(start)\n",
    "\n",
    "## Tokenize words in review\n",
    "start = time.time()\n",
    "reviews_df['tokenized_dirty'] = reviews_df['reviewText'].apply(nltk.word_tokenize)\n",
    "print_elapsed(start)\n",
    "\n",
    "## Remove stop words\n",
    "start = time.time()\n",
    "reviews_df['tokenized_review'] = reviews_df['tokenized_dirty'].apply(lambda tokens: [w for w in tokens if w.lower() not in stop_words])\n",
    "\n",
    "## Perform Part-Of-Speech (POS) tagging on tokens\n",
    "def my_pos_tag(tok_list):\n",
    "    pos_tagged = nltk.pos_tag(tok_list)\n",
    "    tags = {\n",
    "        'n' : wordnet.NOUN,\n",
    "        'v' : wordnet.VERB,\n",
    "        'j' : wordnet.ADJ,\n",
    "        'r' : wordnet.ADV\n",
    "    }\n",
    "    tag_dict = defaultdict(lambda: wordnet.NOUN, tags)\n",
    "    new_tags = [(tok, tag_dict[pos[0].lower()]) for (tok, pos) in pos_tagged]\n",
    "    return new_tags\n",
    "\n",
    "start = time.time()\n",
    "reviews_df['tok/pos'] = reviews_df['tokenized_review'].apply(my_pos_tag)\n",
    "print_elapsed(start)\n",
    "\n",
    "## Stem words in tokenized review\n",
    "start = time.time()\n",
    "reviews_df['stemmed_review'] = reviews_df['tokenized_review'].apply(lambda tokens: [stemmer.stem(t) for t in tokens])\n",
    "print_elapsed(start)\n",
    "\n",
    "## Lemmatize words in tokenized review\n",
    "start = time.time()\n",
    "reviews_df['lemmatized_review'] = reviews_df['tok/pos'].apply(lambda tokens: [lemmatizer.lemmatize(t, pos) for (t, pos) in tokens])\n",
    "print_elapsed(start)\n",
    "\n",
    "print(f'Total execution time: {time.time() - begin}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ccbb4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>tokenized_dirty</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>tok/pos</th>\n",
       "      <th>stemmed_review</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APV13CM0919JD</td>\n",
       "      <td>Amazon,\\nI am shopping for Amazon.com gift car...</td>\n",
       "      <td>[Amazon, ,, I, am, shopping, for, Amazon.com, ...</td>\n",
       "      <td>[Amazon, ,, shopping, Amazon.com, gift, cards,...</td>\n",
       "      <td>[(Amazon, n), (,, n), (shopping, v), (Amazon.c...</td>\n",
       "      <td>[amazon, ,, shop, amazon.com, gift, card, chri...</td>\n",
       "      <td>[Amazon, ,, shop, Amazon.com, gift, card, Chri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3G8U1G1V082SN</td>\n",
       "      <td>I got this gift card from a friend, and it was...</td>\n",
       "      <td>[I, got, this, gift, card, from, a, friend, ,,...</td>\n",
       "      <td>[got, gift, card, friend, ,, best, !, site, mu...</td>\n",
       "      <td>[(got, v), (gift, a), (card, n), (friend, n), ...</td>\n",
       "      <td>[got, gift, card, friend, ,, best, !, site, mu...</td>\n",
       "      <td>[get, gift, card, friend, ,, best, !, site, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A11T2Q0EVTUWP</td>\n",
       "      <td>aren't we going to save trees?! :) People who ...</td>\n",
       "      <td>[are, n't, we, going, to, save, trees, ?, !, :...</td>\n",
       "      <td>[n't, going, save, trees, ?, !, :, ), People, ...</td>\n",
       "      <td>[(n't, r), (going, v), (save, v), (trees, n), ...</td>\n",
       "      <td>[n't, go, save, tree, ?, !, :, ), peopl, compl...</td>\n",
       "      <td>[n't, go, save, tree, ?, !, :, ), People, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A9YKGBH3SV22C</td>\n",
       "      <td>You can always get someone something from Amaz...</td>\n",
       "      <td>[You, can, always, get, someone, something, fr...</td>\n",
       "      <td>[always, get, someone, something, Amazon, safe...</td>\n",
       "      <td>[(always, r), (get, v), (someone, n), (somethi...</td>\n",
       "      <td>[alway, get, someon, someth, amazon, safeti, n...</td>\n",
       "      <td>[always, get, someone, something, Amazon, safe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A34WZIHVF3OKOL</td>\n",
       "      <td>Why take 50 dollars of good money with no limi...</td>\n",
       "      <td>[Why, take, 50, dollars, of, good, money, with...</td>\n",
       "      <td>[take, 50, dollars, good, money, limitations, ...</td>\n",
       "      <td>[(take, v), (50, n), (dollars, n), (good, a), ...</td>\n",
       "      <td>[take, 50, dollar, good, money, limit, ,, turn...</td>\n",
       "      <td>[take, 50, dollar, good, money, limitation, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147189</th>\n",
       "      <td>A2K9WVQW9TLWNK</td>\n",
       "      <td>I always enjoy getting these Gift cards via em...</td>\n",
       "      <td>[I, always, enjoy, getting, these, Gift, cards...</td>\n",
       "      <td>[always, enjoy, getting, Gift, cards, via, ema...</td>\n",
       "      <td>[(always, r), (enjoy, v), (getting, v), (Gift,...</td>\n",
       "      <td>[alway, enjoy, get, gift, card, via, email, lo...</td>\n",
       "      <td>[always, enjoy, get, Gift, card, via, email, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147190</th>\n",
       "      <td>A149ALSR6TPGF7</td>\n",
       "      <td>Worked great</td>\n",
       "      <td>[Worked, great]</td>\n",
       "      <td>[Worked, great]</td>\n",
       "      <td>[(Worked, v), (great, a)]</td>\n",
       "      <td>[work, great]</td>\n",
       "      <td>[Worked, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147191</th>\n",
       "      <td>A2Q066NZCQSCOR</td>\n",
       "      <td>Gift card</td>\n",
       "      <td>[Gift, card]</td>\n",
       "      <td>[Gift, card]</td>\n",
       "      <td>[(Gift, n), (card, n)]</td>\n",
       "      <td>[gift, card]</td>\n",
       "      <td>[Gift, card]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147192</th>\n",
       "      <td>A1KJLWCW7XBS8I</td>\n",
       "      <td>What is there to say, It's a gift card.</td>\n",
       "      <td>[What, is, there, to, say, ,, It, 's, a, gift,...</td>\n",
       "      <td>[say, ,, 's, gift, card, .]</td>\n",
       "      <td>[(say, v), (,, n), ('s, n), (gift, n), (card, ...</td>\n",
       "      <td>[say, ,, 's, gift, card, .]</td>\n",
       "      <td>[say, ,, 's, gift, card, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147193</th>\n",
       "      <td>ANABUB0FRZXRM</td>\n",
       "      <td>No complaints, ordered it and within 5 or so m...</td>\n",
       "      <td>[No, complaints, ,, ordered, it, and, within, ...</td>\n",
       "      <td>[complaints, ,, ordered, within, 5, minutes, r...</td>\n",
       "      <td>[(complaints, n), (,, n), (ordered, v), (withi...</td>\n",
       "      <td>[complaint, ,, order, within, 5, minut, receiv...</td>\n",
       "      <td>[complaint, ,, order, within, 5, minute, recei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147035 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID                                         reviewText  \\\n",
       "0        APV13CM0919JD  Amazon,\\nI am shopping for Amazon.com gift car...   \n",
       "1       A3G8U1G1V082SN  I got this gift card from a friend, and it was...   \n",
       "2        A11T2Q0EVTUWP  aren't we going to save trees?! :) People who ...   \n",
       "3        A9YKGBH3SV22C  You can always get someone something from Amaz...   \n",
       "4       A34WZIHVF3OKOL  Why take 50 dollars of good money with no limi...   \n",
       "...                ...                                                ...   \n",
       "147189  A2K9WVQW9TLWNK  I always enjoy getting these Gift cards via em...   \n",
       "147190  A149ALSR6TPGF7                                       Worked great   \n",
       "147191  A2Q066NZCQSCOR                                          Gift card   \n",
       "147192  A1KJLWCW7XBS8I            What is there to say, It's a gift card.   \n",
       "147193   ANABUB0FRZXRM  No complaints, ordered it and within 5 or so m...   \n",
       "\n",
       "                                          tokenized_dirty  \\\n",
       "0       [Amazon, ,, I, am, shopping, for, Amazon.com, ...   \n",
       "1       [I, got, this, gift, card, from, a, friend, ,,...   \n",
       "2       [are, n't, we, going, to, save, trees, ?, !, :...   \n",
       "3       [You, can, always, get, someone, something, fr...   \n",
       "4       [Why, take, 50, dollars, of, good, money, with...   \n",
       "...                                                   ...   \n",
       "147189  [I, always, enjoy, getting, these, Gift, cards...   \n",
       "147190                                    [Worked, great]   \n",
       "147191                                       [Gift, card]   \n",
       "147192  [What, is, there, to, say, ,, It, 's, a, gift,...   \n",
       "147193  [No, complaints, ,, ordered, it, and, within, ...   \n",
       "\n",
       "                                         tokenized_review  \\\n",
       "0       [Amazon, ,, shopping, Amazon.com, gift, cards,...   \n",
       "1       [got, gift, card, friend, ,, best, !, site, mu...   \n",
       "2       [n't, going, save, trees, ?, !, :, ), People, ...   \n",
       "3       [always, get, someone, something, Amazon, safe...   \n",
       "4       [take, 50, dollars, good, money, limitations, ...   \n",
       "...                                                   ...   \n",
       "147189  [always, enjoy, getting, Gift, cards, via, ema...   \n",
       "147190                                    [Worked, great]   \n",
       "147191                                       [Gift, card]   \n",
       "147192                        [say, ,, 's, gift, card, .]   \n",
       "147193  [complaints, ,, ordered, within, 5, minutes, r...   \n",
       "\n",
       "                                                  tok/pos  \\\n",
       "0       [(Amazon, n), (,, n), (shopping, v), (Amazon.c...   \n",
       "1       [(got, v), (gift, a), (card, n), (friend, n), ...   \n",
       "2       [(n't, r), (going, v), (save, v), (trees, n), ...   \n",
       "3       [(always, r), (get, v), (someone, n), (somethi...   \n",
       "4       [(take, v), (50, n), (dollars, n), (good, a), ...   \n",
       "...                                                   ...   \n",
       "147189  [(always, r), (enjoy, v), (getting, v), (Gift,...   \n",
       "147190                          [(Worked, v), (great, a)]   \n",
       "147191                             [(Gift, n), (card, n)]   \n",
       "147192  [(say, v), (,, n), ('s, n), (gift, n), (card, ...   \n",
       "147193  [(complaints, n), (,, n), (ordered, v), (withi...   \n",
       "\n",
       "                                           stemmed_review  \\\n",
       "0       [amazon, ,, shop, amazon.com, gift, card, chri...   \n",
       "1       [got, gift, card, friend, ,, best, !, site, mu...   \n",
       "2       [n't, go, save, tree, ?, !, :, ), peopl, compl...   \n",
       "3       [alway, get, someon, someth, amazon, safeti, n...   \n",
       "4       [take, 50, dollar, good, money, limit, ,, turn...   \n",
       "...                                                   ...   \n",
       "147189  [alway, enjoy, get, gift, card, via, email, lo...   \n",
       "147190                                      [work, great]   \n",
       "147191                                       [gift, card]   \n",
       "147192                        [say, ,, 's, gift, card, .]   \n",
       "147193  [complaint, ,, order, within, 5, minut, receiv...   \n",
       "\n",
       "                                        lemmatized_review  \n",
       "0       [Amazon, ,, shop, Amazon.com, gift, card, Chri...  \n",
       "1       [get, gift, card, friend, ,, best, !, site, mu...  \n",
       "2       [n't, go, save, tree, ?, !, :, ), People, comp...  \n",
       "3       [always, get, someone, something, Amazon, safe...  \n",
       "4       [take, 50, dollar, good, money, limitation, ,,...  \n",
       "...                                                   ...  \n",
       "147189  [always, enjoy, get, Gift, card, via, email, L...  \n",
       "147190                                    [Worked, great]  \n",
       "147191                                       [Gift, card]  \n",
       "147192                        [say, ,, 's, gift, card, .]  \n",
       "147193  [complaint, ,, order, within, 5, minute, recei...  \n",
       "\n",
       "[147035 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51998d9a",
   "metadata": {},
   "source": [
    "## Dask Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e556fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for operation: 0.12734389305114746\n",
      "Elapsed time for operation: 0.0007479190826416016\n",
      "Elapsed time for operation: 0.001725912094116211\n",
      "Elapsed time for operation: 0.0012979507446289062\n",
      "Elapsed time for operation: 0.1732158660888672\n",
      "Elapsed time for operation: 0.0015239715576171875\n",
      "Elapsed time for operation: 0.0014340877532958984\n",
      "Total execution time: 14.011240005493164\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "start = begin\n",
    "\n",
    "# reviews_dd = dd.read_json(data_path_755MB, orient='records')\n",
    "# reviews_dd = reviews_dd.repartition(npartitions=500)\n",
    "\n",
    "reviews_dd = db.read_text(data_path_50MB).map(json.loads).to_dataframe()\n",
    "reviews_dd = reviews_dd.repartition(npartitions=8)\n",
    "\n",
    "print_elapsed(start)\n",
    "\n",
    "## Drop unwanted columns / keep good ones\n",
    "start = time.time()\n",
    "columns = ['reviewerID', 'reviewText']\n",
    "reviews_dd = reviews_dd[columns]\n",
    "print_elapsed(start)\n",
    "\n",
    "## Drop empty (NaN) rows\n",
    "start = time.time()\n",
    "reviews_dd = reviews_dd.dropna()\n",
    "print_elapsed(start)\n",
    "\n",
    "## Tokenize words in review\n",
    "start = time.time()\n",
    "reviews_dd['tokenized_dirty'] = reviews_dd['reviewText'].apply(nltk.word_tokenize, meta=('reviewText', 'object'))\n",
    "print_elapsed(start)\n",
    "\n",
    "## Remove stop words\n",
    "start = time.time()\n",
    "reviews_dd['tokenized_review'] = reviews_dd['tokenized_dirty'].apply(lambda tokens: [w for w in tokens if w.lower() not in stop_words], meta=('tokenized_dirty', 'object'))\n",
    "\n",
    "\n",
    "## Perform Part-Of-Speech (POS) tagging on tokens\n",
    "def my_pos_tag(tok_list):\n",
    "    pos_tagged = nltk.pos_tag(tok_list)\n",
    "    tags = {\n",
    "        'n' : wordnet.NOUN,\n",
    "        'v' : wordnet.VERB,\n",
    "        'j' : wordnet.ADJ,\n",
    "        'r' : wordnet.ADV\n",
    "    }\n",
    "    tag_dict = defaultdict(lambda: wordnet.NOUN, tags)\n",
    "    new_tags = [(tok, tag_dict[pos[0].lower()]) for (tok, pos) in pos_tagged]\n",
    "    return new_tags\n",
    "\n",
    "start = time.time()\n",
    "reviews_dd['tok/pos'] = reviews_dd['tokenized_review'].apply(my_pos_tag, meta=('tok/pos', 'object'))\n",
    "print_elapsed(start)\n",
    "\n",
    "## Stem words in tokenized review\n",
    "start = time.time()\n",
    "reviews_dd['stemmed_review'] = reviews_dd['tokenized_review'].apply(lambda tokens: [stemmer.stem(t) for t in tokens], meta=('tokenized_review', 'object'))\n",
    "print_elapsed(start)\n",
    "\n",
    "## Lemmatize words in tokenized review\n",
    "start = time.time()\n",
    "reviews_dd['lemmatized_review'] = reviews_dd['tok/pos'].apply(lambda tokens: [lemmatizer.lemmatize(t, pos) for (t, pos) in tokens], meta=('tok/pos', 'object'))\n",
    "print_elapsed(start)\n",
    "\n",
    "final_dd = reviews_dd.head(5)\n",
    "\n",
    "print(f'Total execution time: {time.time() - begin}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2400890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>tokenized_dirty</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>tok/pos</th>\n",
       "      <th>stemmed_review</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APV13CM0919JD</td>\n",
       "      <td>Amazon,\\nI am shopping for Amazon.com gift car...</td>\n",
       "      <td>[Amazon, ,, I, am, shopping, for, Amazon.com, ...</td>\n",
       "      <td>[Amazon, ,, shopping, Amazon.com, gift, cards,...</td>\n",
       "      <td>[(Amazon, n), (,, n), (shopping, v), (Amazon.c...</td>\n",
       "      <td>[amazon, ,, shop, amazon.com, gift, card, chri...</td>\n",
       "      <td>[Amazon, ,, shop, Amazon.com, gift, card, Chri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3G8U1G1V082SN</td>\n",
       "      <td>I got this gift card from a friend, and it was...</td>\n",
       "      <td>[I, got, this, gift, card, from, a, friend, ,,...</td>\n",
       "      <td>[got, gift, card, friend, ,, best, !, site, mu...</td>\n",
       "      <td>[(got, v), (gift, a), (card, n), (friend, n), ...</td>\n",
       "      <td>[got, gift, card, friend, ,, best, !, site, mu...</td>\n",
       "      <td>[get, gift, card, friend, ,, best, !, site, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A11T2Q0EVTUWP</td>\n",
       "      <td>aren't we going to save trees?! :) People who ...</td>\n",
       "      <td>[are, n't, we, going, to, save, trees, ?, !, :...</td>\n",
       "      <td>[n't, going, save, trees, ?, !, :, ), People, ...</td>\n",
       "      <td>[(n't, r), (going, v), (save, v), (trees, n), ...</td>\n",
       "      <td>[n't, go, save, tree, ?, !, :, ), peopl, compl...</td>\n",
       "      <td>[n't, go, save, tree, ?, !, :, ), People, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A9YKGBH3SV22C</td>\n",
       "      <td>You can always get someone something from Amaz...</td>\n",
       "      <td>[You, can, always, get, someone, something, fr...</td>\n",
       "      <td>[always, get, someone, something, Amazon, safe...</td>\n",
       "      <td>[(always, r), (get, v), (someone, n), (somethi...</td>\n",
       "      <td>[alway, get, someon, someth, amazon, safeti, n...</td>\n",
       "      <td>[always, get, someone, something, Amazon, safe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A34WZIHVF3OKOL</td>\n",
       "      <td>Why take 50 dollars of good money with no limi...</td>\n",
       "      <td>[Why, take, 50, dollars, of, good, money, with...</td>\n",
       "      <td>[take, 50, dollars, good, money, limitations, ...</td>\n",
       "      <td>[(take, v), (50, n), (dollars, n), (good, a), ...</td>\n",
       "      <td>[take, 50, dollar, good, money, limit, ,, turn...</td>\n",
       "      <td>[take, 50, dollar, good, money, limitation, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                         reviewText  \\\n",
       "0   APV13CM0919JD  Amazon,\\nI am shopping for Amazon.com gift car...   \n",
       "1  A3G8U1G1V082SN  I got this gift card from a friend, and it was...   \n",
       "2   A11T2Q0EVTUWP  aren't we going to save trees?! :) People who ...   \n",
       "3   A9YKGBH3SV22C  You can always get someone something from Amaz...   \n",
       "4  A34WZIHVF3OKOL  Why take 50 dollars of good money with no limi...   \n",
       "\n",
       "                                     tokenized_dirty  \\\n",
       "0  [Amazon, ,, I, am, shopping, for, Amazon.com, ...   \n",
       "1  [I, got, this, gift, card, from, a, friend, ,,...   \n",
       "2  [are, n't, we, going, to, save, trees, ?, !, :...   \n",
       "3  [You, can, always, get, someone, something, fr...   \n",
       "4  [Why, take, 50, dollars, of, good, money, with...   \n",
       "\n",
       "                                    tokenized_review  \\\n",
       "0  [Amazon, ,, shopping, Amazon.com, gift, cards,...   \n",
       "1  [got, gift, card, friend, ,, best, !, site, mu...   \n",
       "2  [n't, going, save, trees, ?, !, :, ), People, ...   \n",
       "3  [always, get, someone, something, Amazon, safe...   \n",
       "4  [take, 50, dollars, good, money, limitations, ...   \n",
       "\n",
       "                                             tok/pos  \\\n",
       "0  [(Amazon, n), (,, n), (shopping, v), (Amazon.c...   \n",
       "1  [(got, v), (gift, a), (card, n), (friend, n), ...   \n",
       "2  [(n't, r), (going, v), (save, v), (trees, n), ...   \n",
       "3  [(always, r), (get, v), (someone, n), (somethi...   \n",
       "4  [(take, v), (50, n), (dollars, n), (good, a), ...   \n",
       "\n",
       "                                      stemmed_review  \\\n",
       "0  [amazon, ,, shop, amazon.com, gift, card, chri...   \n",
       "1  [got, gift, card, friend, ,, best, !, site, mu...   \n",
       "2  [n't, go, save, tree, ?, !, :, ), peopl, compl...   \n",
       "3  [alway, get, someon, someth, amazon, safeti, n...   \n",
       "4  [take, 50, dollar, good, money, limit, ,, turn...   \n",
       "\n",
       "                                   lemmatized_review  \n",
       "0  [Amazon, ,, shop, Amazon.com, gift, card, Chri...  \n",
       "1  [get, gift, card, friend, ,, best, !, site, mu...  \n",
       "2  [n't, go, save, tree, ?, !, :, ), People, comp...  \n",
       "3  [always, get, someone, something, Amazon, safe...  \n",
       "4  [take, 50, dollar, good, money, limitation, ,,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d5a77",
   "metadata": {},
   "source": [
    "## Spark Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093a71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for operation: 6.844664096832275\n",
      "Elapsed time for operation: 0.050984859466552734\n",
      "Elapsed time for operation: 0.042524099349975586\n",
      "Elapsed time for operation: 0.053797006607055664\n",
      "Elapsed time for operation: 0.13108396530151367\n",
      "Elapsed time for operation: 0.025659799575805664\n",
      "Elapsed time for operation: 0.03692007064819336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 9.849095106124878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "start = begin\n",
    "\n",
    "spark_df = spark.read.json(data_path_50MB)\n",
    "print_elapsed(start)\n",
    "\n",
    "## Drop unwanted columns / keep good ones\n",
    "start = time.time()\n",
    "columns = ['reviewerID', 'reviewText']\n",
    "spark_df = spark_df.select(*columns)\n",
    "print_elapsed(start)\n",
    "\n",
    "## Drop empty (NaN) rows\n",
    "start = time.time()\n",
    "spark_df = spark_df.dropna()\n",
    "print_elapsed(start)\n",
    "\n",
    "## Tokenize words in review\n",
    "start = time.time()\n",
    "udf_tokenize = udf(nltk.word_tokenize)\n",
    "spark_df = spark_df.withColumn(\"tokenized_dirty\", udf_tokenize(spark_df.reviewText))\n",
    "print_elapsed(start)\n",
    "\n",
    "## Remove stop words in reviews\n",
    "start = time.time()\n",
    "udf_clean = udf(lambda tokens: [w for w in tokens if w.lower() not in stop_words])\n",
    "spark_df = spark_df.withColumn(\"tokenized_review\", udf_clean(spark_df.tokenized_dirty))\n",
    "\n",
    "## Perform Part-Of-Speech (POS) tagging on tokens\n",
    "def my_pos_tag(tok_list):\n",
    "    pos_tagged = nltk.pos_tag(tok_list)\n",
    "    tags = {\n",
    "        'n' : wordnet.NOUN,\n",
    "        'v' : wordnet.VERB,\n",
    "        'j' : wordnet.ADJ,\n",
    "        'r' : wordnet.ADV\n",
    "    }\n",
    "    tag_dict = defaultdict(lambda: wordnet.NOUN, tags)\n",
    "    new_tags = [(tok, tag_dict[pos[0].lower()]) for (tok, pos) in pos_tagged]\n",
    "    return new_tags\n",
    "\n",
    "start = time.time()\n",
    "udf_pos = udf(my_pos_tag)\n",
    "spark_df = spark_df.withColumn('tok_pos', udf_pos(spark_df.tokenized_review))\n",
    "print_elapsed(start)\n",
    "\n",
    "## Stem words in tokenized review\n",
    "start = time.time()\n",
    "udf_stem = udf(lambda tokens: [stemmer.stem(t) for t in tokens])\n",
    "spark_df = spark_df.withColumn(\"stemmed_text\", udf_stem(spark_df.tokenized_review))\n",
    "print_elapsed(start)\n",
    "\n",
    "## Lemmatize words in tokenized review\n",
    "start = time.time()\n",
    "udf_lemmatize = udf(lambda tokens: [lemmatizer.lemmatize(t, pos) for (t, pos) in tokens])\n",
    "spark_df = spark_df.withColumn(\"lemmatized_text\", udf_lemmatize(spark_df.tok_pos))\n",
    "print_elapsed(start)\n",
    "   \n",
    "final_df = spark_df.head(5)\n",
    "\n",
    "print(f'Total execution time: {time.time() - begin}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be653dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
